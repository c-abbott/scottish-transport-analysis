{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as path_effects\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import json\n",
    "import os\n",
    "import descartes\n",
    "from shapely.geometry import Point, Polygon\n",
    "from datetime import datetime\n",
    "\n",
    "# Params\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q0: Basic EDA + Tidying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* General introduction to data set\n",
    "* Selection criteria - what was signal, what was noise\n",
    " * Collapsing HGVs into one type\n",
    " * Column type / format\n",
    "* Pulling in additional data sources for base df_tidy: population\n",
    "* One major transformation was making sure the the names of the local authorities had parity across all the different data sets we sourced so utilising data-frame joins did not fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('data/dft_rawcount_region_id_3.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # Quickly viewing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all') # Basic EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy = df.copy() # Tidy dataset storage\n",
    "\n",
    "# Cols to drop\n",
    "rm_cols = ['region_id', 'region_name', 'local_authority_id', 'road_type',\n",
    "           'start_junction_road_name', 'end_junction_road_name',\n",
    "           'year', 'easting', 'northing', 'link_length_miles', 'hgvs_2_rigid_axle',\n",
    "           'hgvs_3_rigid_axle', 'hgvs_3_or_4_articulated_axle',\n",
    "           'hgvs_4_or_more_rigid_axle', 'hgvs_5_articulated_axle',\n",
    "           'hgvs_6_articulated_axle']\n",
    "\n",
    "# Drop cols\n",
    "df_tidy.drop(rm_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Vehicle Labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = ['bikes', 'motorcycles', 'cars', 'buses', 'lgvs', 'hgvs'] # More interpretable labels\n",
    "name_mappings = dict(zip(df_tidy.columns[9:-1], new_names)) # Creating dict of label mappings\n",
    "df_tidy.rename(columns=name_mappings, inplace=True) # Renaming columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidy Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_motor_vehicles --> all_vehicles (include bikes)\n",
    "df_tidy['all_vehicles'] = df_tidy['bikes'] + df_tidy['motorcycles'] + df_tidy['cars'] + df_tidy['buses'] + \\\n",
    "                          df_tidy['lgvs'] + df_tidy['hgvs']\n",
    "\n",
    "# New column for specifying whether road is: M, A, B, C, U\n",
    "df_tidy = df_tidy.assign(\n",
    "            road_type = lambda dataframe: dataframe['road_name'].map(lambda road_name: road_name[0]))\n",
    "\n",
    "# Convert count_date to datetime format\n",
    "df_tidy['count_date'] = pd.to_datetime(df['count_date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in population statistics\n",
    "# CITATION NEEDED\n",
    "pop_df = pd.read_csv('data/scotland-mid-year-pop-est-19.csv', header=None)\n",
    "\n",
    "# Rename columns\n",
    "pop_df.rename(columns={0: 'local_authority_name', 1: 'population'}, inplace=True)\n",
    "\n",
    "# Convert population to int\n",
    "pop_df.population = pop_df.population.str.replace(',', '')\n",
    "pop_df.population = pop_df.population.astype('int') \n",
    "\n",
    "# String replaces to avoid join issues\n",
    "pop_df.local_authority_name = pop_df.local_authority_name.str.replace('Na h-Eileanan Siar', 'Eilean Siar')\n",
    "df_tidy.local_authority_name = df_tidy.local_authority_name.str.replace('Comhairle nan Eilean Siar', 'Eilean Siar')\n",
    "df_tidy.local_authority_name = df_tidy.local_authority_name.str.replace('&', 'and')\n",
    "\n",
    "# Overwrite df_tidy with full outer join with population data`\n",
    "df_tidy = pd.merge(df_tidy, pop_df, on='local_authority_name', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tidy.head(1000) # Final check of tidy dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1: Bikes observed per 10k residents per local auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Wanted to visualise bicycles, and thought that observations per 10k residents would be interesting\n",
    "* When we saw that the highest number was for the Orkney Islands which is one of the least densely populated authorities in Scotland, we wanted to see any relationships between observations and population\n",
    "* Initially, we thought about embedding pop. figures on the bar chart but realised that a choropleth map would be visually engaging and clearer\n",
    "\n",
    "### Caveats\n",
    "1. Count data of bikes is assumed to be representative of the prevalence of bikes in the authority\n",
    "2. A bike count within a local authority maps to that bike actually belonging to that authority\n",
    "3. Double counting effects are ignored\n",
    "\n",
    "This is because bikes are not registered vehicles and hence this assumption has to be made. We think this is a reasonable assumption since bikes are used for micro-mobility in the majority of cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple helper function to perform \n",
    "# divide one pd df column by another\n",
    "def div_series(df):\n",
    "    return df['bikes'].sum() * 10000 / float(df['population'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting relevant data for bike viz\n",
    "bikes_cols = ['local_authority_name', 'bikes', 'population']\n",
    "df_bikes = df_tidy[bikes_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_per_10k_residents = df_bikes.groupby(['local_authority_name'], \n",
    "                                           as_index=True).apply(div_series).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of bikes per 10k residents\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (10, 25))\n",
    "pal = sns.light_palette(\"seagreen\", n_colors=40, reverse=True)\n",
    "sns.barplot(x = bikes_per_10k_residents, y = bikes_per_10k_residents.index, palette=pal)\n",
    "ax.set_title(\"DFT 2000-2019 Cycle Counts per 10k Residents \\nper Scottish Local Authority\",\n",
    "            pad=10, loc = \"left\", fontdict={'weight':'heavy', 'color':'black'}, fontsize=25)\n",
    "ax.set_ylabel(\"\")\n",
    "ax.set_xlabel(\"Cycles counts per 10k residents\", fontsize=25, labelpad=10)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.figtext(x=.75, y=0, \n",
    "            s='Source: DFT Road Traffic Statistics', \n",
    "            fontdict={'style':'oblique', 'color':'black'})\n",
    "plt.grid(which='major', axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: MapViz of Bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Acquire topographical data (in TopoJSON format) that we converted into a map using GeoPandas - focus on authority borders\n",
    "* Played around with the starting position when map is loaded due to the fact that Scotland has a few far-flung islands up North\n",
    "* Choropleth map was coloured using population data with a single colour gradient - we thought this would look cleaner and less distracting compared to using multiple colours\n",
    "* We wanted to display the bikes data points on each local authority and took two different approaches - one was to find the mean of lat/long in our data set, and one was to approximate central coordinates for each authority manually (with the Power of Google Maps) which gave us more control\n",
    " * Aside: we realised that as the coordinates in the data set are based on positions on roads, the mean coordinates are heavily biased towards road clusters\n",
    "* We explored a number of different visual options for the choropleth map by changing 'tiles', highlighting, etc.\n",
    "* An interesting exercise was parsing the TopoJSON data to pull out relevant authority names so we could use them as keys for our visualisation\n",
    "* Finally, we ended up with circles located on the mean-central coordinates, with the radius controlled a scalar multiple of bike observations - scaling was of high magnitude for clearer visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting relevant columns for mapviz\n",
    "map_cols = ['count_point_id', 'local_authority_name', 'count_date', 'road_name',\n",
    "            'hour', 'direction_of_travel', 'latitude', 'longitude', 'population']\n",
    "map_df = df_tidy[map_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually finding central lat and long of \n",
    "# each local authority\n",
    "auth_names = sorted(map_df.local_authority_name.unique())\n",
    "lat_longs = [[57.148499575046166, -2.0994503154974553],[57.273760025881934, -2.5166643080179645],[56.72768401017168, -2.9246922126651884],[56.09740006583508, -5.505829190157146],[55.95233877595505, -3.188860106840768],[56.14959079238047, -3.7457616021792624],[55.085097679793755, -3.9648777663637222],[56.46547771536677, -2.9702673126999213],[55.465299446108205, -4.307460244966752],[55.950679905225755, -4.21793961543706],[55.943997191276125, -2.7324635644378654],[55.75505725179119, -4.362197202163319],[58.24343874214309, -6.382783267363518],[56.00349190992439, -3.7933138794341983], [56.246895135851844, -3.087199713717091],[55.85890878015006, -4.246879570599694],[57.47148264549703, -4.918077719700579],[55.910241417028985, -4.73843337649973],[55.8380756961132, -3.091164797971764],[57.507658214268204, -3.2238412189671544], [55.72279452380807, -4.743315946865488], [55.87990377885493, -3.943898088843739], [59.02526102084918, -3.006499055095088], [56.55895608244633, -3.8058868668882613], [55.84937262539755, -4.534918906544666], [55.580570268563, -2.726163579854028], [60.33439464263681, -1.2344978915362006], [55.29083618369606, -4.6958972343105625], [55.59988380366663, -3.7749667034686474], [56.22513721244209, -4.338586907406815], [55.982771806368184, -4.5149571176594625], [55.88803749019023, -3.570496063254735]]\n",
    "coords_dict = dict(zip(auth_names, lat_longs)) \n",
    "coords_df = pd.DataFrame.from_dict(coords_dict, orient='index', columns=['cent_lat', 'cent_long'])\n",
    "coords_df.reset_index(level=0, inplace=True)\n",
    "coords_df.rename(columns={'index':'local_authority_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finidng mean lat and long of each local authority\n",
    "# and storing in new df\n",
    "coords_df_tidy = df_tidy[['local_authority_name', 'latitude', 'longitude']]\n",
    "coords_df_tidy = coords_df_tidy.groupby('local_authority_name')[['latitude', 'longitude']].mean()\n",
    "coords_df_tidy.rename(columns={'latitude':'cent_lat', 'longitude':'cent_long'}, inplace=True) # Renaming columns\n",
    "coords_df_tidy.reset_index(level = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full outer SQL join of map_df and coords_df_tidy\n",
    "map_df = pd.merge(map_df, coords_df_tidy, on='local_authority_name', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching dft authority names with external authority names\n",
    "# JSON file is of local authority borders for choropleth map\n",
    "auth_geo = os.path.join(os.getcwd(), 'data/local_auth.json')\n",
    "with open(auth_geo) as f:\n",
    "    scotland_topo = json.load(f)\n",
    "topo_names = []\n",
    "for i in range(32):\n",
    "    topo_names.append(scotland_topo['objects']['lad']['geometries'][i]['properties']['LAD13NM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://towardsdatascience.com/choropleth-maps-with-folium-1a5b8bcdd392\n",
    "# Initialise map of Scotland\n",
    "scotland_bright = folium.Map(location=[57.8906712, -4.2026458], zoom_start=6.25, tiles='cartodbpositron')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create choloropleth of population data\n",
    "choropleth = folium.Choropleth(geo_data = scotland_topo,              \n",
    "    topojson = 'objects.lad',\n",
    "    key_on ='feature.properties.LAD13NM',\n",
    "    data = map_df,\n",
    "    columns = ['local_authority_name', 'population'], \n",
    "    name ='choropleth',                                   \n",
    "    fill_color = 'Blues', \n",
    "    fill_opacity = 1, # Prev 0.7\n",
    "    line_opacity = 0.5, # Prev 0.2\n",
    "    highlight = True,\n",
    "    legend_name='Population',\n",
    "    smooth_factor=0,\n",
    ").add_to(scotland_bright) # Prev scotland\n",
    "\n",
    "# Add labels indicating local authority name\n",
    "style_function = \"font-size: 12px\"\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['LAD13NM'], style=style_function, labels=False))\n",
    "\n",
    "# Add layer control\n",
    "folium.LayerControl().add_to(scotland_bright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes_viz_df = bikes_per_10k_residents.to_frame()\n",
    "bikes_viz_df.rename(columns={0:'bikes_10k'}, inplace=True)\n",
    "bikes_viz_df.reset_index(level=0, inplace=True) # Resetting index\n",
    "bikes_viz_df = pd.merge(bikes_viz_df, coords_df_tidy, on='local_authority_name', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add circles whose sizes represent bikes per 10k residents\n",
    "normalizer = max(bikes_viz_df['bikes_10k'])\n",
    "for auth_name in auth_names:\n",
    "    folium.Circle(\n",
    "        location = [bikes_viz_df.loc[bikes_viz_df['local_authority_name'] == auth_name]['cent_lat'].values[0], \n",
    "                bikes_viz_df.loc[bikes_viz_df['local_authority_name'] == auth_name]['cent_long'].values[0]],\n",
    "        radius = float(bikes_viz_df.loc[bikes_viz_df['local_authority_name'] == auth_name]['bikes_10k'].values[0]*7e4),\n",
    "        color = 'mediumseagreen',\n",
    "        fill_color = 'mediumseagreen',\n",
    "        popup = f\"Bike density per 10k residents: {round(bikes_viz_df.loc[bikes_viz_df['local_authority_name'] == auth_name]['bikes_10k'].values[0], 3)}\",\n",
    "        tooltip=auth_name\n",
    "    ).add_to(scotland_bright)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scotland_bright"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3: roads + vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We had a series of visualisations of the entire range of vehicles\n",
    "* In this one we wanted to see there was a difference in vehicle counts by month\n",
    "* We noticed that the trend was typically in the following order: ...\n",
    "* Across most months the trend in vehicle counts was consistent\n",
    "* What was interesting was the nominal number of counts seemed to be quite low for specific months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We hypothesised that DfT do not go out to look for specific vehicles (otherwise the trends would be quite different) but the reported counts are at least function of the different types of roads, given no other data\n",
    "* So we created a similar visualisation but faceted it with the type of road and noticed:\n",
    " * For the months where fewer vehicles were observed, for certain types of roads, no counts were recorded at all, and for others, there was significant variance over the years\n",
    " * This leads us to hypothesise the reported counts are also a function of availability of DfT staff - for example, July and August are typically school holidays so most working parents (and non-parents) are on vacation, and November is the lead up to Christmas (also it's cold!)\n",
    "* Note:\n",
    " * 278 A roads\n",
    " * 206 B roads\n",
    " * 9   M roads\n",
    " * Undefined C/U roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_road_letters = np.vectorize(lambda string: string[0])\n",
    "\n",
    "for road_counts in zip(*np.unique(extract_road_letters(df_tidy.road_name.unique()), return_counts = True)):\n",
    "    if road_counts[1] > 1:\n",
    "        print(f\"There are {road_counts[1]} {road_counts[0]} roads.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining months for ordering purposes\n",
    "months = [\"March\", \"April\", \"May\", \"June\", \"July\", \"August\",\n",
    "          \"September\", \"October\", \"November\"]\n",
    "\n",
    "# Extract relevant columns for observing variation of counts\n",
    "# over the different months for different vehicles\n",
    "vehicle_cols = ['count_date', 'bikes', 'motorcycles', 'cars', 'buses', 'lgvs', 'hgvs']\n",
    "vehicle_df = df_tidy.copy()\n",
    "vehicle_df = vehicle_df[vehicle_cols]\n",
    "# Create new column for month name\n",
    "vehicle_df.loc[:,'month'] = vehicle_df['count_date'].dt.month_name()\n",
    "# Ordering month_df chronologically\n",
    "vehicle_df.loc[:,'month'] = pd.Categorical(vehicle_df['month'], categories=months, ordered=True)\n",
    "vehicle_df.sort_values(by='month', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid', font_scale=1.5)\n",
    "\n",
    "# Create the PairGrid\n",
    "vg = sns.PairGrid(vehicle_df.sort_values('cars', ascending=False),\n",
    "                 x_vars=vehicle_df.columns[1:-1], y_vars=['month'],\n",
    "                 height=10, aspect=.25)\n",
    "plt.subplots_adjust(top=.875)\n",
    "vg.fig.suptitle(\"DFT Distribution of Vehicles Counts by Month 2000-2019\",  \n",
    "                fontdict={'weight':'bold', 'color':'black'},\n",
    "                fontsize=30)\n",
    "\n",
    "# Draw a scatter plot using stripplot function\n",
    "vg.map(sns.stripplot, size=7.5, orient='h', marker='o',\n",
    "       palette='flare_r', linewidth=1, edgecolor='none',  alpha=.5)\n",
    "\n",
    "# Use semantically meaningful titles for the columns\n",
    "titles = [\"Bikes\", \"Motorcycles\", \"Cars\", \"Buses\",\n",
    "          \"LGVS\", \"HGVS\"]\n",
    "\n",
    "for ax, title in zip(vg.axes.flat, titles):\n",
    "    # Set a different title for each axes\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    \n",
    "    # Make the grid horizontal instead of vertical\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.yaxis.grid(False)\n",
    "\n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns for observing variation of counts\n",
    "# over the different months for different road_types\n",
    "roads_cols = ['count_date', 'road_type']\n",
    "roads_df = df_tidy[roads_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivoting data wider so M, A, B, C, U become columns\n",
    "roads_df = roads_df.pivot_table(index=['count_date'], columns=['road_type'], aggfunc=len, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_df.reset_index(level=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making type_df chronologically ordered\n",
    "roads_df['month'] = roads_df['count_date'].dt.month_name()\n",
    "roads_df['month'] = pd.Categorical(roads_df['month'], categories=months, ordered=True)\n",
    "roads_df.sort_values(by='month', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordering type_df columns\n",
    "roads_cols = ['count_date', 'month', 'M', 'A', 'B', 'C', 'U']\n",
    "roads_df = roads_df.reindex(columns=roads_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid', font_scale=1.5)\n",
    "# Create the PairGrid\n",
    "roads_g = sns.PairGrid(roads_df.sort_values('A', ascending=False),\n",
    "                 x_vars=roads_df.columns[2:], y_vars=['month'],\n",
    "                 height=10, aspect=.25)\n",
    "plt.subplots_adjust(top=.835)\n",
    "roads_g.fig.suptitle(\"DFT Distribution of Road Type Counts \\nby Month 2000-2019\",  \n",
    "                fontdict={'weight':'bold', 'color':'black'},\n",
    "                fontsize=30)\n",
    "\n",
    "\n",
    "# Draw a scatter plot using stripplot function\n",
    "roads_g.map(sns.barplot, palette=\"flare_r\")\n",
    "\n",
    "# Use semantically meaningful titles for the columns\n",
    "titles = [\"M\", \"A\", \"B\", \"C\", \"U\"]\n",
    "\n",
    "for ax, title in zip(roads_g.axes.flat, titles):\n",
    "    # Set a different title for each axes\n",
    "    ax.set_title(title, fontsize=20)\n",
    "    # Make the grid horizontal instead of vertical\n",
    "    ax.xaxis.grid(False)\n",
    "    ax.yaxis.grid(True)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    \n",
    "sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~Q1: Bar chart of [X] longest roads showing start and end locations~\n",
    "\n",
    "### Method\n",
    "* Filter by distinguishing road name \n",
    "* Ignore U and C roads \n",
    "* We have start and end junctions (general locations)\n",
    "* How do we calculate distance?\n",
    "    1. Add up link lengths\n",
    "    2. Verify with Google Maps\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~Q2: Local authorities managing number of roads - mapviz - fixed point in time~\n",
    "\n",
    "### Outcome\n",
    "* 2019 map of roads managed\n",
    "* Static map of Scotland with gradient colour scheme\n",
    "\n",
    "### Method\n",
    "* Group by `local_authority_name`, `count_id`\n",
    "* Break down total number of roads per authority into `road_names`\n",
    "* Possible weight matrix to give larger, busier roads a larger influence in the map - don't want to give U and C thes same weighting as M and A roads\n",
    "* In `road_name` variable, cut string such that it's only a single character\n",
    "\n",
    "### Stretch and Challenge\n",
    "* Maintenance data to observe which authority spends the most on maintainance\n",
    "\n",
    "### Extra Packages:\n",
    "* folium\n",
    "* geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Q3: Interactive visualization of the usage of Cycles on motorways in Scotland ~distribution of vehicles over each type of road over the past [X] years~ from 2000 to 2019\n",
    "\n",
    "### Outcome\n",
    "* x-axis: discrete vehicle type data e.g.  cars, bikes, buses, hgvs, lgvs etc\n",
    "* y-axis: type of road e.g. M, A, B, C, U\n",
    "* Scatter point for each category where size indicates prevalence of that type of vehicle on that type of road\n",
    "* Slider which shows variation of data over [X] years\n",
    "\n",
    "\n",
    "### Method\n",
    "* Group C and U roads\n",
    "* Normalize scatter points by \\pi*R^2\n",
    "\n",
    "\n",
    "### Stretch and Challenge\n",
    "* We have dotted line outline of average of previous 5 years giving the reader some indication of growth/reduction\n",
    "* x-axis: as emojis\n",
    "\n",
    "\n",
    "### Extra packages\n",
    "* plotly - used to vary the datapoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Out of curiosity we wanted to see the usage of HGVs on different types of roads (we hypothesised that it would be unlikely to see them on U/C roads - or at least very few of them\n",
    "* To do this we tried a different map set - a shape file of the road network in Scotland\n",
    "* We filtered the data based on HGVs, and only retained rows where at least one HGV was observed\n",
    "* We had to use the `Shapely` library to convert the coordinates into a tuple-esque coordinate object, and then  plotted the points using `GeoPandas` \n",
    "* The resulting visualisation wasn't as scandalous as we would have liked so we thought out a different case: would you ever expect to see cycles on Motorways (which is illegal)?\n",
    "* It turned out that a particular stretch of some motorways saw a particularly large number of cycles observed (for a motorway and given the illegality, anything more than 0 counts as large!):\n",
    " * M8 on 11/06/00\n",
    " * M90 on 11/04/00 and 23/06/00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique roads, because we can\n",
    "unique_motorways = df_tidy.loc[df_tidy.road_type == 'M'].road_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting HGV-only data\n",
    "bikem_cols = ['count_date', 'hour', 'road_name', 'road_type', 'latitude', 'longitude', 'bikes']\n",
    "bikem_df = df_tidy[bikem_cols]\n",
    "bikem_df = bikem_df.loc[bikem_df['bikes'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikem_df.loc[(bikem_df['road_type']=='M')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Point objects for plotting HGV counts and their locations\n",
    "# on gpd map\n",
    "geometry = [Point(xy) for xy in zip(bikem_df['longitude'], bikem_df['latitude'])]\n",
    "# Specifying coordinate reference system\n",
    "crs = {'init': 'EPSG:4326'}\n",
    "bikem_df.drop(['latitude', 'longitude'], inplace=True, axis = 1) # drop unnessecary cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.GeoDataFrame(bikem_df, crs = crs, geometry = geometry) # Create geodf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in external shape file of Scottish roads\n",
    "scotland_roads = gpd.read_file('data/roads.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scotland_auth_shape = gpd.read_file('pub_las.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(figsize = (12, 20))\n",
    "scotland_roads.plot(ax = axis, color = 'gray', alpha = 0.2)\n",
    "#scotland_auth_shape.plot(ax = axis, color = 'white', edgecolor = 'black')\n",
    "#geo_df[geo_df['road_type'] == 'U'].plot(ax = axis, markersize = 15, color = 'red', marker = 'o', label = 'U')\n",
    "#geo_df[geo_df['road_type'] == 'C'].plot(ax = axis, markersize = 15, color = 'green', marker = 'o', label = 'C')\n",
    "geo_df[geo_df['road_type'] == 'M'].plot(ax = axis, markersize = 200, color = 'firebrick', marker = 'x', label = 'M')\n",
    "plt.legend(prop = {'size': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4: Time of day viz?\n",
    "\n",
    "### Outcome\n",
    "* x-axis: Hours of the day (07:00 - 18:00)\n",
    "* y-axis-1: `all_vehicles`\n",
    "* y-axis-2: types of vehicle (faceted plot)\n",
    "* Light alpha filled densities\n",
    "\n",
    "### Method\n",
    "* Get hours day\n",
    "* Group vehicle count by hour type\n",
    "* Further subset those counts by vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Answering one of the provided questions, we wanted a nice-looking distribution plot of vehicle counts per hour of day\n",
    "* We decided to use the scheme and some formatting from the `FiveThirtyEight` theme\n",
    "* As this is a graph we expect many people to provide, we wanted to make it look a little snazzier by directly annotating the vehicle type on the graph itself in a visually engaging way\n",
    "* Observations:\n",
    " * Follows an expected trend with peaks in the morning (commuter traffic) and evening\n",
    " * Typically more observations at the end of day suggesting it is a mix of commuter and leisure traffic (going out for the evening after work)\n",
    " * HGVs bucked this trend which we surmise because their work involves driving them to and from depots and distribution centres during working hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tod_df = df_tidy[['hour'] + new_names] # Extracting relevant variables\n",
    "tod_df = tod_df.groupby('hour').sum()  # Find total counts of each vehicle at every hour\n",
    "tod_df.reset_index(level=0, inplace=True) # Index with numbers not names\n",
    "tod_df = tod_df.melt(id_vars='hour', var_name='vehicle_type') # Pivot longer\n",
    "tod_df.vehicle_type = tod_df.vehicle_type.astype('category')  # Converting datatype to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant data to plot\n",
    "x = tod_df.hour.unique()\n",
    "y1 = tod_df.loc[tod_df.vehicle_type=='cars']['value']\n",
    "y2 = tod_df.loc[tod_df.vehicle_type=='lgvs']['value']\n",
    "y3 = tod_df.loc[tod_df.vehicle_type=='hgvs']['value']\n",
    "y4 = tod_df.loc[tod_df.vehicle_type=='buses']['value']\n",
    "y5 = tod_df.loc[tod_df.vehicle_type=='motorcycles']['value']\n",
    "y6 = tod_df.loc[tod_df.vehicle_type=='bikes']['value']\n",
    "y = [y1, y2, y3, y4, y5, y6] # Amalgamate into single list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['CARS', 'LGVS', 'HGVS', 'BUSES', 'MBIKES', 'BIKES']\n",
    "xticks_ = np.arange(7, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "# Plotting facetgrid manually\n",
    "fig, axes = plt.subplots(6, 1, sharex=False, sharey=False, figsize=(16, 32), facecolor='white')\n",
    "plt.subplots_adjust(top=.94)\n",
    "\n",
    "fig.suptitle(\"DFT Distribution of Vehicles Counts \\nby Hour 2000-2019\",  \n",
    "                fontdict={'weight':'bold', 'color':'black'},\n",
    "                fontsize=40)\n",
    "hues = ['#e5ae38', '#8b8b8b', '#6d904f', '#fc4f30', '#810f7c', '#008fd5']\n",
    "for i, ax in enumerate(axes):\n",
    "    sns.lineplot(data=tod_df, x='hour', y=y[i], ax=ax, hue='vehicle_type')\n",
    "    ax.fill_between(x, y[i], color=hues[i], alpha=0.35)\n",
    "    ax.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticks(xticks_),\n",
    "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.0f')),\n",
    "    ax.get_legend().remove()\n",
    "    t = ax.annotate(f\"{labels[i]}\", \n",
    "                xy=(10,10), \n",
    "                xycoords='data', \n",
    "                textcoords='axes fraction', \n",
    "                xytext=(.94,.075),\n",
    "                ha='right',\n",
    "                fontsize=60,\n",
    "                fontweight='bold',\n",
    "                color='white')\n",
    "    t.set_path_effects([path_effects.Stroke(linewidth=5, foreground=hues[i]),\n",
    "                       path_effects.Normal()])\n",
    "    ax.set_facecolor(\"white\")\n",
    "    ax.xaxis.grid(True)\n",
    "    ax.yaxis.grid(False)\n",
    "    sns.despine(left=True, bottom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODOs for Q4:\n",
    "\n",
    "* Add all hours to x-axis\n",
    "* Format y-axis, and change labels\n",
    "* Add hover on hour points to read values\n",
    "* Display legend of colour <--> vehicle_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5: Bikes observed per 10k residents / capita per local authority \n",
    "\n",
    "### Caveats\n",
    "1. Count data of bikes is assumed to be representative of the prevalence of bikes in the authority\n",
    "2. A bike count within a local authority maps to that bike actually belonging to that authority\n",
    "3. Double counting effects are ignored\n",
    "\n",
    "This is because bikes are not registered vehicles and hence this assumption has to be made. We think this is a reasonable assumption since bikes are used for micro-mobility in the majority of cases.\n",
    "\n",
    "### Outcome\n",
    "* Horizontal bar chart ordered in descending order\n",
    "\n",
    "### Method\n",
    "* Get population data and store in tidy dataframe\n",
    "* Plot the data\n",
    "\n",
    "## Additional\n",
    "* Encode or visualise population data\n",
    "* Bikes per 10,000 residents - same as log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
